---
title: "Least Squares Regression"
author: "M Loecher"
output:
   html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the Advertising data set 
```{r}
Advertising <- read.csv("../../data/Advertising.csv", row.names=1)
```

and write a function that creates a scatter plot each of Sales versus one of the three other variables and overlays the mean:

```{r, fig.width=10, echo = TRUE}

r = round(cor(Advertising),2)
m = colMeans(Advertising)

plotAds = function(x="TV", myData=Advertising, col = "blue",m=m){
  plot(myData[,x], myData$Sales, pch=20, col = col, xlab = x, ylab = "Sales");grid();
  title(paste("r=", round(cor(myData[,x], myData$Sales),2)))
  m = colMeans(Advertising[,c(x,"Sales")])
  points(m[x],m["Sales"], col="red",pch=19,cex=1.75)
}

par(mfrow=c(1,3),cex=1)
plotAds("TV")
plotAds("Radio", col = "darkgreen")
plotAds("Newspaper", col = "purple")


```


#### Review: Straight Line Equation

Let us recall that a straight line can be defined either by just two points or by its slope and intercept:
$$ 
y = m \cdot x + b \mbox{,  or more fancy:  } y = \beta_1 \cdot x + \beta_0
$$
The slope is simply $\beta_1 = \Delta y/\Delta x$.

Given two points $(x_1,y_1), (x_2,y_2)$ please derive the expressions that yield $\beta_1$ and $\beta_0$.
```{r, echo=FALSE}
plot(c(1,2),c(3,5), xlab="",ylab="",pch=19, cex=1.5, xlim = c(0,3), ylim = c(1,6), col ="blue");grid()
lines(c(1,2),c(3,3), col = "green", lwd=2)
lines(c(2,2),c(3,5), col = "green", lwd=2)
lines(c(0,2.5),c(1,6), col = "red", lwd=1.5)
text(1,2.6,expression(paste("(", x[1], ",", y[1], ")")), cex=1.5, col ="blue")
text(2,4.6,expression(paste("(", x[2], ",", y[2], ")")), cex=1.5, col ="blue")
```

$$
\beta_1 = \frac{\Delta y}{\Delta x} =  \frac{y_2-y_1}{x_2-x_1}
$$

#### Task 1. Write a function that takes as input two points and returns the slope and intercept.

```{r}
LineEqn = function(p1=c(1,2), p2=c(3,5)){
  dY = p2[2]-p1[2]
  dX = p2[1]-p1[1]
  m=dY/dX
  b=p2[2] - m*p2[1]
  return(c(m,b))
}

LineEqn()

LineEqn2 = function(x=c(1,3), y=c(2,5)){
  dY = diff(y)
  dX = diff(x)
  m=dY/dX
  b=y[2] - m*x[2]
  return(c(m,b))
}
```



#### Task 2. Eyeball a point on the far left or far right of the graph. Take this point as well as the mean as an in put to the function from above to get a slope and intercept. Modify the function from above to overlay a line with these parameters.

```{r}
plot(Sales ~ TV, data = Advertising)

mb=LineEqn2(x=c(50,150), y=c(9,14))

abline(mb[2],mb[1], col = "blue")
#myFirstModel = lm(Sales ~ TV, data = Advertising)
#abline(myFirstModel, col = 2)

#summary(myFirstModel)
 
```

### Covariance, Correlation

$$
COV = s_{xy} = \frac{1}{n} \cdot  \sum_{i=1}^{n} {(x_i- \bar{x})(y_i- \bar{y})} 
$$

$$
 s_{xy} = \overline{x \cdot y} - \bar{y} \cdot \bar{x} 
$$

$$
 r = \frac{s_{xy}}{s_x s_y} =  \frac{\frac{1}{n} \cdot  \sum_{i=1}^{n} {(x_i- \bar{x})(y_i- \bar{y})}}{\sqrt{\frac{1}{n} \cdot  \sum_{i=1}^{n} {(x_i- \bar{x})^2}} \sqrt{\frac{1}{n} \cdot  \sum_{i=1}^{n} {(y_i- \bar{y})^2}} }
$$
$$
  = \frac{\frac{1}{n} \ldots}{\sqrt{\frac{1}{n} \ldots} \sqrt{\frac{1}{n} \ldots}}
$$
#### Task 3. Compute the "best" slope 

```{r}
#best slope: cov/var

beta1 = cov(Advertising$TV,Advertising$Sales)/var(Advertising$TV )
beta0 = mean(Advertising$Sales) - beta1*mean(Advertising$TV)

```


#### Task 4. Compute the residuals and their sum

#### Task 5. Verify the least squares property of the regression line

```{r}
myYhat = 6.5 + 0.05*Advertising$TV
mye = Advertising$Sales - myYhat
myRSS = sum(mye^2)

myRSS
```


```{r}
plot(Sales ~ TV, data = Advertising)

mb=LineEqn2(x=c(50,150), y=c(9,14))

abline(mb[2],mb[1], col = "blue")
myFirstModel = lm(Sales ~ TV, data = Advertising)
abline(myFirstModel, col = 2)

 
```

#### Task 6. Looking at Sales alone, what is your best "prediction" and what is the unvertainty that goes with it, expressed in two different ways.

```{r}
hist(Advertising$Sales);grid()
```

#### Task 7. What is the remaning uncertainty "after the regression"?

```{r}
summary(myFirstModel)
```

