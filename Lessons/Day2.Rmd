---
title: "Day 2: Modeling in R"
author: "Markus Loecher, Berlin School of Economics and Law"
output:
   html_document:
    #variant: markdown_github
    toc: true
    number_sections: true
    self_contained: no
    toc_depth: 2
    toc_float: true
    fig_caption: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
baseR = FALSE
library(pander)
```


# Data manipulation

## Data: nycflights13

To explore the basic data manipulation verbs of dplyr, we'll start with the built in
`nycflights13` data frame. This dataset contains all `r nrow(nycflights13::flights)` flights that departed from New York City in 2013. The data comes from the US [Bureau of Transportation Statistics](http://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&Link=0), and is documented in `?nycflights13`

```{r}
library(nycflights13)
dim(flights)
head(flights)
```

dplyr can work with data frames as is, but if you're dealing with large data, it's worthwhile to convert them to a `tbl_df`: this is a wrapper around a data frame that won't accidentally print a lot of data to the screen.

### Single table verbs

Dplyr aims to provide a function for each basic verb of data manipulation:

* `filter()` (and `slice()`)
* `arrange()`
* `select()` (and `rename()`)
* `distinct()`
* `mutate()` (and `transmute()`)
* `summarise()`
* `sample_n()` (and `sample_frac()`)

If you've used plyr before, many of these will be familar.

### Filter rows with `filter()`

`filter()` allows you to select a subset of rows in a data frame. The first argument is the name of the data frame. The second and subsequent arguments are the expressions that filter the data frame:

For example, we can select all flights on January 1st with:

```{r}
library(dplyr)
filter(flights, month == 1, day == 1)
```

This is equivalent to the more verbose code in base R:

```{r, eval = FALSE}
flights[flights$month == 1 & flights$day == 1, ]
```

To select rows by position, use `slice()`:

```{r}
slice(flights, 1:10)
```

### Arrange rows with `arrange()`

`arrange()` works similarly to `filter()` except that instead of filtering or selecting rows, it reorders them. It takes a data frame, and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns:

```{r}
arrange(flights, year, month, day)
```

Use `desc()` to order a column in descending order:

```{r}
arrange(flights, desc(arr_delay))
```


### Select columns with `select()`

Often you work with large datasets with many columns but only a few are actually of interest to you. `select()` allows you to rapidly zoom in on a useful subset using operations that usually only work on numeric variable positions:

```{r}
# Select columns by name
select(flights, year, month, day)
# Select all columns between year and day (inclusive)
select(flights, year:day)
# Select all columns except those from year to day (inclusive)
select(flights, -(year:day))
```


You can rename variables with `select()` by using named arguments:

```{r}
select(flights, tail_num = tailnum)
```

But because `select()` drops all the variables not explicitly mentioned, it's not that useful. Instead, use `rename()`:

```{r}
rename(flights, tail_num = tailnum)
```

### Extract distinct (unique) rows

Use `distinct()`to find unique values in a table:

```{r}
distinct(flights, tailnum)
distinct(flights, origin, dest)
```

(This is very similar to `base::unique()` but should be much faster.)

### Add new columns with `mutate()`

Besides selecting sets of existing columns, it's often useful to add new columns that are functions of existing columns.  This is the job of `mutate()`:

```{r}
mutate(flights,
  gain = arr_delay - dep_delay,
  speed = distance / air_time * 60)
```

mutate allows you to refer to columns that you've just created:

```{r}
mutate(flights,
  gain = arr_delay - dep_delay,
  gain_per_hour = gain / (air_time / 60)
)
```


### Summarise values with `summarise()`

The last verb is `summarise()`. It collapses a data frame to a single row (this is exactly equivalent to `plyr::summarise()`):

```{r}
summarise(flights,
  delay = mean(dep_delay, na.rm = TRUE))
```

Below, we'll see how this verb can be very useful.


### Grouped operations

These verbs are useful on their own, but they become really powerful when you apply them to groups of observations within a dataset. In dplyr, you do this by with the `group_by()` function. It breaks down a dataset into specified groups of rows. When you then apply the verbs above on the resulting object they'll be automatically applied "by group". Most importantly, all this is achieved by using the same exact syntax you'd use with an ungrouped object.


In the following example, we split the complete dataset into individual planes and then summarise each plane by counting the number of flights (`count = n()`) and computing the average distance (`dist = mean(Distance, na.rm = TRUE)`) and arrival delay (`delay = mean(ArrDelay, na.rm = TRUE)`). We then use ggplot2 to display the output.

```{r, warning = FALSE, message = FALSE, fig.width = 6}
by_tailnum <- group_by(flights, tailnum)
delay <- summarise(by_tailnum,
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dist < 2000)

# Interestingly, the average delay is only slightly related to the
# average distance flown by a plane.
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
  geom_point(aes(size = count), alpha = 1/2) +
  geom_smooth() +
  scale_size_area()
```

You use `summarise()` with __aggregate functions__, which take a vector of values and return a single number. There are many useful examples of such functions in base R like `min()`, `max()`, `mean()`, `sum()`, `sd()`, `median()`, and `IQR()`. dplyr provides a handful of others:

* `n()`: the number of observations in the current group

* `n_distinct(x)`:the number of unique values in `x`.

* `first(x)`, `last(x)` and `nth(x, n)` - these work
  similarly to `x[1]`, `x[length(x)]`, and `x[n]` but give you more control
  over the result if the value is missing.

For example, we could use these to find the number of planes and the number of flights that go to each possible destination:

```{r}
destinations <- group_by(flights, dest)
summarise(destinations,
  planes = n_distinct(tailnum),
  flights = n()
)
```


## Titanic


```{r, echo = TRUE }
train <- read.csv("data/TitanicTrain.csv")
```


The disaster was famous for saving "women and children first", so let's take a look at the Sex and Age variables to see if any patterns are evident. We'll start with the gender of the passengers. After reloading the data into R, take a look at the summary of this variable:

```{r, echo = TRUE }
round(prop.table(table(train$Sex, train$Survived),1),2)
```


Let's create a new variable, "Child", to indicate whether the passenger is below the age of 18:

```{r, echo = TRUE }
train$Child <- 0
train$Child[train$Age < 18] <- 1
```

Now we want to create a table with both gender and age to see the survival proportions for different subsets.
Recall the dplyr version of the aggregate function:

```{r, echo = TRUE}
suppressPackageStartupMessages(require(dplyr))
summarise(group_by(train, Sex, Child), round(mean(Survived),2), length(Survived))

```


While the class variable is limited to a manageable 3 values, the fare is again a continuous variable that needs to be reduced to something that can be easily tabulated. Let's bin the fares into less than $10, between $10 and $20, $20 to $30 and more than $30 and store it to a new variable:

```{r, echo = TRUE}
train$Fare2 <- '30+'
 train$Fare2[train$Fare < 30 & train$Fare >= 20] <- '20-30'
 train$Fare2[train$Fare < 20 & train$Fare >= 10] <- '10-20'
train$Fare2[train$Fare < 10] <- '<10'
```

* Use the summarise function to compute the proportions and  in each group defined by child, gender and Fare2:

```{r, echo = FALSE}
SurvProp = summarise(group_by(train, Child, Fare2, Sex), round(mean(Survived),2), length(Survived))

SurvProp = SurvProp[order(SurvProp$`round(mean(Survived), 2)`),]
```

* Find strong differences between male/female survival probabilities.
* Partition your data into even finer subgroups, e.g. age and/or embarkation port and repeat.

```{r, echo = FALSE}
summarise(group_by(train, Child, Fare2, Sex, Embarked), round(mean(Survived),2), length(Survived))

```



----------------------------

# Descriptive statistics

## Measures of Central tendency

```{r}

mean(flights$dep_delay)

mean(flights$dep_delay, na.rm=T)

median(flights$dep_delay, na.rm=T)

#robustness
mean(flights$dep_delay, na.rm=T, trim = 0.1)
```


## Dispersion measures

Only sample stdev is included!

```{r}
#var

sd(flights$dep_delay, na.rm=T)

IQR(flights$dep_delay, na.rm=T)

mad(flights$dep_delay, na.rm=T)

```


## Descriptive boxplots

```{r}
#define our own transformation
require(scales) # trans_new() is in the scales library
sign_sqrt_trans = function() trans_new("sign_sqrt", function(x) sign(x)*sqrt(abs(x)), function(x) sign(x)*x^2)

```

### Delays by carrier

```{r}
if (baseR){
  boxplot(arr_delay ~ carrier, data=flights)
  grid()
} else {
  p = ggplot(flights, aes( carrier,arr_delay))
  p + geom_boxplot() + coord_trans(y="sign_sqrt") #+ scale_y_sqrt()
}
```

There appear to be significant delays by time-of-day:

```{r, fig.width=10}
if (baseR){
  boxplot(arr_delay ~ hour, data=flights)
  grid()
} else {
  p = ggplot(flights, aes( factor(hour),arr_delay))
  p + geom_boxplot() + coord_trans(y="sign_sqrt") #+ scale_y_sqrt()
}

```

----------------------------

# Basic statistical tests 

I have prepared a data file for you:

```{r, echo=TRUE, fig.width=10}
print(load("data/BirthWeights.rda"))
class(x$gender)
#split the plotting region into 2 columns:
par(mfrow=c(1,2))
boxplot(dbirwt ~ gender, data=x)
hist(x$dbirwt, xlab="birth weight [g]")
```

## remove outliers

```{r}
#either:
ii = which(x$dbirwt> 8000)
x = x[-ii,]

#or:
x = subset(x, dbirwt <= 8000)

```


## density plot

```{r, echo=TRUE}
library(ggplot2)
ggplot(x, aes(dbirwt, fill=gender)) + geom_density(alpha=.5) + 
  scale_fill_manual(values = c("orange", "purple")) # +   theme(legend.position = "none")
```


### t-test

Can we detect the difference in birth weights?

```{r}
boys = subset(x, gender == "male")$dbirwt
girls = subset(x, gender == "female")$dbirwt
  
t.test(x=boys, y=girls)
```

Would a small sample suffice?

```{r}
set.seed(1234)

b=sample(boys,100);g=sample(girls,100)

t.test(b,g)
```

What about these non integer degrees of freedom??


### F-test for variances

```{r}
var.test(b,g)
```


### prop-test

```{r}
(gs = table(train$Sex, train$Survived))
prop.test(gs)

```

### Exact Binomial Test

```{r}
binom.test(gs[1,2:1], p=0.75)

```


----------------------------

# Linear Models

## correlation 

#### Are arrival and departure delay correlated?

```{r, fig.width=8}
if (baseR){
  plot(arr_delay ~ dep_delay, data=flights, pch=20,cex=0.5,col=carrier)
  grid()
} else {
  p = ggplot(flights, aes( dep_delay,arr_delay, col=carrier ))
  p + geom_point( alpha=0.5, size=1) + coord_trans(x="sign_sqrt", y="sign_sqrt") # +  geom_smooth(method=lm) 
}


cor(flights$dep_delay,flights$arr_delay, use = "complete.obs",method = "pearson")
#slooow    
#cor(flights$dep_delay,flights$arr_delay, use = "complete.obs",method = "kendall")
  
#cor(flights$dep_delay,flights$arr_delay, use = "complete.obs",method = "spearman")

Shortdelays = filter(flights, abs(arr_delay)<100 & abs(dep_delay)<100)

cor(Shortdelays$dep_delay,Shortdelays$arr_delay, use = "complete.obs",method = "pearson")

#plot(arr_delay ~ dep_delay,data=Shortdelays)
```


## simple regression 

### mpg vs. weight


```{r}
library(ISLR);data(Auto)
plot(mpg ~ weight, data = Auto,col = rgb(0,0,1,0.5), pch=20,xlim=c(250, 7000), ylim = c(0,45));grid()
LSfit = lm(mpg ~ weight, data = Auto)

#overlay regression line
abline(LSfit, col=2)

#summary
summary(LSfit)

#diagnostics
plot(LSfit, c(1,2,5))

```

**Tasks**

1. Predict mpg for a car that weighs 5000 lbs.
2. Confidence Interval for slope
3. Are the least squares assumptions met?
4. Add 3 outliers to the data: 
  * weight=500, mpg = 40
  * weight=$10^4$, mpg = 80
  * weight=3000, mpg = 80

Points that fall horizontally far from the line are points of high leverage; these points
can strongly influence the slope of the least squares line. If one of these high leverage
points does appear to actually invoke its in
uence on the slope of the line then we call it an in
uential point. Usually we can say
a point is influential if, had we fitted the line without it, the influential point would have
been unusually far from the least squares line.


```{r, fig.width=12, fig.height = 6}
par(mfrow=c(1,3), cex=1.4)

outlrs = cbind(weight=c(500,10000,3000),mpg=c(40,80,80))
Auto2 = Auto

fit=list()
for (i in 1:3){
  Auto2[1,c("weight","mpg")] = outlrs[i,]
  
  plot(mpg ~ weight, data = Auto2,col = rgb(1,0.894,0.769,0.5), pch=20);grid()
  #overlay regression line
  abline(LSfit, col=2, lwd=2.5)
  fit[[i]] = lm(mpg ~ weight, data = Auto2) 
  points(Auto2[1,c("weight","mpg")], col = i+2, pch = 18, cex = 2)
  #overlay regression line
  abline(fit[[i]], col=i+2,lwd=2, lty=2)
  #plot(fit[[i]],5)
}


```


### global warming

```{r}
Global <- scan("data/global.dat")
 Global.ts <- ts(Global, st = c(1856, 1), end = c(2005, 12),
fr = 12)
 Global.annual <- aggregate(Global.ts, FUN = mean)
 plot(Global.ts);grid()
 
Last35 <- window(Global.ts, start=c(1970, 1), end=c(2005, 12))
 Last35Yrs <- time(Last35)
 fitAD=lm(Last35 ~ Last35Yrs)
summary(fitAD)
  abline(fitAD,col=2)


```



## logistic regression

Back to the Titanic data. How did the survival probability depend on age?

```{r}
fit = glm(Survived ~ Age, family = binomial, data = train)
pander(summary(fit)$coefficients)
```

**Give a precise interpretation of the slope**


### dummies/factors

```{r}
fit = glm(Survived ~ Pclass, family = binomial, data = train)
pander(summary(fit)$coefficients)
```


```{r}
fit = glm(Survived ~ factor(Pclass), family = binomial, data = train)
pander(summary(fit)$coefficients)
```

```{r}
fit = glm(Survived ~ factor(Pclass) -1, family = binomial, data = train)
pander(summary(fit)$coefficients)
```




## multiple regression 


```{r}
fit1=glm(Survived ~ Pclass + Sex + Age + Fare, data = train, family=binomial)
pander(summary(fit1)$coefficients)

```


Second model: take out the (highly significant) variable passenger class

```{r}
fit2=glm(Survived ~ Pclass + Sex + Age, data = train, family=binomial)
pander(summary(fit2)$coefficients)
```

**Why did the status of the variable Fare change from non-significant to highly significant ?**




## ANOVA
 

### Comparison of nested models

See page 130 in the ISL book.

The anova() function performs a hypothesis
test comparing the two models. The null hypothesis is that the two models
fit the data equally well, and the alternative hypothesis is that the full
model is superior. 



```{r}
 fit1=lm(Survived ~ Pclass + Sex + Age + Fare, data = train)
 fit2=lm(Survived ~ Pclass + Sex + Age , data = train)

anova(fit1,fit2)
```

### Differences in means

Are there significant differences in delays by airport in the flight data?

```{r, fig.width=10}
if (baseR){
  boxplot(arr_delay ~ origin, data=flights)
  grid()
} else {
  p = ggplot(flights, aes( factor(origin),arr_delay))
  p + geom_boxplot() + coord_trans(y="sign_sqrt") #+ scale_y_sqrt()
}

```

Can we use ANOVA to determine its significance?

Yes, a linear model:

```{r}
summary(lm(arr_delay ~ factor(origin) -1, data = flights))

myAOV = aov(arr_delay ~ factor(origin) -1, data = flights)

summary(myAOV)


```


The ANOVA F-test answers the question whether there are significant 
differences in the K population means. However, it does not provide us with any 
information about how they differ. Therefore when you reject $H_0$
in ANOVA, 
additional analyses are required to determine what is driving the difference in 
means.  The function `pairwise.t.test` computes the pairwise comparisons 
between group means with corrections for multiple testing.


```{r}
pairwise.t.test(flights$arr_delay, flights$origin, adjust="bonferroni")
```


Another multiple comparisons procedure is Tukey???s method. The function 
`TukeyHSD()` creates a set of confidence intervals on the differences between means with the specified family-wise 
probability of coverage:



```{r}
TukeyHSD(myAOV)
```


