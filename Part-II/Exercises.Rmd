---
title: "Exercises, Part II"
author: "M Loecher"
output:
   html_document:
    #variant: markdown_github
    toc: true
    #number_sections: true
    self_contained: yes
    toc_depth: 3
    toc_float: true
    fig_caption: true
    code_folding: hide
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning =FALSE)
```

## ROC curves, revisited

```{r, echo=FALSE}
myROC = function(fits, 
                 TrueCategory=train$Survived,
                 train
){
  ROC = list()
  lab = names(fits)
  M=length(fits)
  
  for (k in 1:M ){
    cat("working on", lab[k], "\n")
    if (lab[k]=="rpart" | lab[k]== "party")
       preds = predict(fits[[k]], newdata=train, type="prob")[,2]
    else 
      preds = predict(fits[[k]], newdata=train, type="response")
    FPR=FNR=TPR=vector()
    pCutoffs = seq(0.025,0.975, by = 0.01)
    
    for (i in 1:length(pCutoffs)){
      SurvPreds = factor(preds > pCutoffs[i], levels = c(TRUE,FALSE))
      ConfMat = table(SurvPreds, TrueCategory)
      TN = sum(ConfMat[,1])#true negatives
      TP = sum(ConfMat[,2])#true positives
      
      FPR[i] = ConfMat[2,1]/TN # False Positive Rate
      FNR[i] = ConfMat[1,2]/TP # False Negative Rate
      #TPR proportion of positives that are correctly identified
      TPR[i] = ConfMat[2,2]/TP
    }
    ROC[[k]] = cbind(FPR,TPR)
  }
  
  plot(FPR ~ TPR, data = ROC[[1]], type="l", lwd=2, main = "ROC curve", xlim=c(0,1), ylim=c(0,1));grid()
  if (M>1)
    for (k in 2:M)
     lines(FPR ~ TPR, data = ROC[[k]], col=k,lwd=2)
  
  legend("bottomright", col=1:M,lwd=2,legend=lab)
}

```

Using AUC ("area under the curve") as a metric, compare the classification accuracy of the following model, w.r.t. the Titanic data:

1. logistic regression
2. Classification tree from *rpart*
3. Classification tree from *partykit*

```{r, echo = FALSE}
train <- read.csv("../data/TitanicTrain.csv")
train$Survived=factor(train$Survived)

fit1 = glm(Survived ~ Sex + Age + Pclass, family = binomial, data = na.omit(train))
library(rpart)
fit2 = rpart(Survived ~ Sex + Age + Pclass, data = train)
library(partykit)
fit3 = ctree(Survived ~ Age + Sex + Pclass, data= train)

fits=list(fit1, fit2, fit3);names(fits)=c("glm", "rpart", "party")
myROC(fits,train=train)
```

## Understanding Trees

(a) Sketch the tree corresponding to the partition of the predictor space illustrated in the left-hand panel of the Figure below. The numbers inside the boxes indicate the mean of $Y$ within each region.

![Tree Partition](figures/Fig8.12.png)

```{r, eval=FALSE, fig.height=8,fig.width=10}
knitr::include_graphics("figures/Fig8.12.png")
```


(b) Create a diagram similar to the left-hand panel of the Figure, using the tree illustrated in the right-hand panel of the same figure. You should divide up the predictor space into the correct regions, and indicate the mean for each region.

Solution

(a)

*If $X_1 \ge 1$ then 5, else if $X_2 \ge 1$ then 15, else if $X_1 < 0$ then 3, else if $X_2 <0$ then 10, else 0.*

(b)

```{r}
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = c(0.21))
```

## Bagging

Write your own code that averages 100 bootstrapped trees and evaluate the results for the Boston data.

## Random Forests

Fit a few random forests to the "Boston" data using a variety of values for the "mtry" and "ntree" parameters. Create a plot displaying the test error resulting from random forests on this data set for a more comprehensive range of values for "mtry" and "ntree". Describe the results obtained.


------------------------------
Solution

```{r, eval=FALSE}
library(MASS)
library(randomForest)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston) / 2)
Boston.train <- Boston[train, -14]
Boston.test <- Boston[-train, -14]
Y.train <- Boston[train, 14]
Y.test <- Boston[-train, 14]
rf.boston1 <- randomForest(Boston.train, y = Y.train, xtest = Boston.test, ytest = Y.test, mtry = ncol(Boston) - 1, ntree = 500)
rf.boston2 <- randomForest(Boston.train, y = Y.train, xtest = Boston.test, ytest = Y.test, mtry = (ncol(Boston) - 1) / 2, ntree = 500)
rf.boston3 <- randomForest(Boston.train, y = Y.train, xtest = Boston.test, ytest = Y.test, mtry = sqrt(ncol(Boston) - 1), ntree = 500)
plot(1:500, rf.boston1$test$mse, col = "green", type = "l", xlab = "Number of Trees", ylab = "Test MSE", ylim = c(10, 19))
lines(1:500, rf.boston2$test$mse, col = "red", type = "l")
lines(1:500, rf.boston3$test$mse, col = "blue", type = "l")
legend("topright", c("m = p", "m = p/2", "m = sqrt(p)"), col = c("green", "red", "blue"), cex = 1, lty = 1)
```

*We may see that the Test MSE is very high for a single tree, it decreases as the number of trees increases. Also the Test MSE for all predictors is higher than for half the predictors or the square root of the number of predictors.*
